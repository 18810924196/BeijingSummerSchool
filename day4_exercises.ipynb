{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4: Convergence orders of Langevin discretizations and Monte-Carlo error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For today's exercises you will need to load the following packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.integrate\n",
    "\n",
    "from miniMD import models\n",
    "from miniMD import integrators\n",
    "from miniMD import outputshedulers as outp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "In today's first exercise we will take a closer look at the discretization error in the Leimkuhler Matthews and the Euler-Maruyama method when applied to the under overdamped Langevin equation\n",
    "\n",
    "$$\n",
    "\\dot{q} = - \\nabla U(q) + \\sqrt{2 \\beta^{-1}} \\dot{W}.\n",
    "$$\n",
    "\n",
    "For this purpose we will consider the following simple cosine potential which is defined on the periodic domain $[0,2\\pi)$:\n",
    "\n",
    "$$\n",
    "U(q) = \\cos(q), q \\in [0,2\\pi),\n",
    "$$\n",
    "\n",
    "The class `CosineModel` in ./miniMD/models.py implements this potential. It also implements the function `apply_boundary_conditions(self, q)`, which resolves the periodic boundary conditions.\n",
    "\n",
    "- Create an instance of `CosineModel` with default parameter values. Plot the potential function on the interval and the associated Gibbs density at unit temperature on the inveral $[0,2\\pi)$. For the computation of the Gibbs density you can use the below code snippet: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Tk_B = 1.0\n",
    "model = models.CosineModel()\n",
    "gibbs_not_normalized = lambda q: np.exp(-Tk_B*model.comp_potential(q))\n",
    "Z,err =  scipy.integrate.quad(gibbs_not_normalized,0,2*np.pi)\n",
    "gibbs = lambda q: gibbs_not_normalized(q)/Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we are going to evaluate the convergence order for the Leimkuhler-Matthews method and the Euler-Maruyama method in the stepsize $h$ as $h\\rightarrow 0$ of the error in ergodic avergages,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{E}(\\varphi,h) &:= \\lim_{N\\rightarrow \\infty} \\left | \\frac{1}{N}\\sum_{n=0}^{N-1} \\varphi(q_n) - \\int \\varphi(q) \\rho_{\\beta}(q) d q \\right |\\\\\n",
    "&=\\left | \\int  \\varphi(q) \\rho_{\\beta}(q) d q - \\int   \\varphi(q)\\widehat{\\rho}_{h,\\beta}(q) d q \\right |\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where \n",
    "$$\\rho_{\\beta}(q) = \\frac{1}{Z} \\exp(-\\beta U(q)),$$\n",
    "is the density of the associated Gibbs-measure, and $\\widehat{\\rho}_{h,\\beta}(q)$ is the invariant measure of the discrete dynamics (see also slide 40 from of day 3 of the lectures for a definition of the ergodic error).\n",
    "\n",
    "In what follows we investigate the  behaviour of $\\mathcal{E}(\\varphi,h)$ for the choices  $$\\varphi(q) := {\\bf 1}_{S_i}(q)= \\begin{cases} 1 &if ~q \\in S\\\\ 0 & if ~q \\not\\in S \\end{cases}, $$ with  $S_i:=[\\frac{i}{12} \\pi,\\frac{i+1}{12}\\pi], ~ i=0,1,2,\\dots,11.$.\n",
    "\n",
    "- Compute (numerically) reference solutions `ref_solutions`, i.e., compute the values of the integrals \n",
    "$$\n",
    "\\int  {\\bf 1}_{S_i}(q) \\rho_{\\beta}(q) d q\n",
    "$$\n",
    "Start with the below code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbins = 12\n",
    "q_bins = np.linspace(0.0,2.0*np.pi,nbins+1)\n",
    "ref_solutions = np.zeros(nbins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reduce the number of time steps $N$ we need to compute to get a good estimate of\n",
    "$$\n",
    "\\int  {\\bf 1}_{S_i}(q) \\widehat{\\rho}_{h,\\beta}(q) d q\n",
    "$$\n",
    "we use a few tricks to reduce the computaional load (Python is quite slow...). First, we will use 1000 replicas to compute the above estimates, and secondly we will initialise the system in equilirbium, i.e., we will sample the initial values of $q$ at the beginning of the simulation from the Gibbs measure $\\rho_\\beta(q)d q$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate 1000 random i.i.d. initial values sampled from the Gibbs measure\n",
    "dim = 1000 \n",
    "q0 = np.zeros(dim)\n",
    "for i in range(dim):\n",
    "    acc = False\n",
    "    while (not acc):\n",
    "        u = np.random.uniform(0,2*np.pi)\n",
    "        v = np.random.uniform(0,1)\n",
    "        if v < gibbs_not_normalized(u)/np.exp(Tk_B):\n",
    "            q0[i] = u\n",
    "            acc =True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute estimates using either the Euler-Maruyama integrator or the Leimkuhler-Matthews method with different step sizes. We will use trajectories of length T=10000$ (physical time) to compute these estimates. Usually, finding the right range of stepsizes is quite tedious. Therefore, these are provided for you in the below code snippet as `h_vec`. Fill in the missing parts in the below code snippet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T=10000 # Physical time\n",
    "n_stepsizes = 5 \n",
    "h_vec = np.logspace(-.3,0.3, n_stepsizes)\n",
    "'''\n",
    "create an instance of the cosine model with dim=1000  \n",
    "'''\n",
    "i=0\n",
    "approx_solutions = np.zeros([n_stepsizes,nbins])\n",
    "for h in h_vec:\n",
    "    print(i)\n",
    "    '''\n",
    "    Initialize \n",
    "        - the integrator with stepsize h and the above specified model\n",
    "        - an instance \"op\" of BufferedOutputsheduler with the appropiate number of time steps so\n",
    "            that a trajectory of physical time T is generated\n",
    "        - run the integrator with initial values q0 \n",
    "        \n",
    "    '''\n",
    "    approx_solutions[i,:] = np.histogram(op.traj_q,q_bins, density=True)[0] # Collect the histogram of the i-th simulation run\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you are using your own implementation of the Leimkuhler-Matthews method, make sure that between the position update and the force computation, the periodic boundary conditions are resolved, i.e., insert the function apply_boundary_conditions with the appropiate arguments after the positon update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the error for each observable. Choose one to create a plot \"step size vs error\" in a loglog plot. You may want to include the plot of a first and second order line for orientation, i.e., include plots showing \"step size vs (step size)/2\" and \"step size vs (step size)^2/10\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 (Weak error vs. error in ergodic averages)\n",
    "\n",
    "In yesterday's lecture you learned that while the error in ergodic averages of the  Leimkuhler-Matthews method converges as $O(h^2)$ as $h \\rightarrow 0$, the weak error of the Leimkuhler-Matthews method converges as $O(h)$ as $h \\rightarrow 0$. In what follows we will verify this property numerically. Recall that for time $T>0$, the weak error is defined as\n",
    "\n",
    "$$\n",
    "\\mathcal{E}(\\varphi,h,T) = \\left |\\mathbb{E}(\\varphi(q_{Nh}) - \\mathbb{E}(\\varphi(q(T)))\\right |, Nh = T,\n",
    "$$\n",
    "\n",
    "where in the case of the exact solution of the SDE, $q(T)$ the expectation is taken with respect to the Brownian motion, and in the case of the numerical approximation, $q_{Nh}$ the expectation is taken with respect to the random increment in each timestep. \n",
    "\n",
    "- Leimkuhler-Matthews Method, (weak order 1, ergodic error order 2)\n",
    "- Euler-Maruyama Method, (weak order 1, ergodic error order 1) \n",
    "\n",
    "We use a similar setup as the one which we used in exercise 1, i.e., we use again the potential function\n",
    "\n",
    "$$\n",
    "U(q) = \\cos(q), q \\in [0,2\\pi),\n",
    "$$\n",
    "\n",
    "and evaluate the error for the collection of observables \n",
    "$$\\varphi(q) := {\\bf 1}_{S_i}(q)= \\begin{cases} 1 &if ~q \\in S\\\\ 0 & if ~q \\not\\in S \\end{cases}, $$ with  $S_i:=[\\frac{i}{12} \\pi,\\frac{i+1}{12}\\pi], ~ i=0,1,2,\\dots,11.$\n",
    "\n",
    "**However,** unlike in the first exercise, we will initialize the particles outside of equilibrium, and measure the weak error at finite times $T=1$, and $T=4$ (physical time) using a reference solution, which was computed using a high order scheme with very small step size.\n",
    "\n",
    "- create an instance of the class `CosineModel` with the dimension parameter `dim` set to $10^6$.\n",
    "- using the LeimkuhlerMatthews method sample trajectories of length $T=1$ and $T=4$ (physical time) using stepsizes of length $h = 1,1/2,1/3,1/4,1/5$. As an outputsheduler you should create an instance `op` of the class `HistogramOutputsheduler`, which at each time step computes a historgram of the monitored variables. After each simulation run you can access the trajectory of histograms as `op.traj_bins_q`. For each simulation run save the histogram corresponding to the last time step, i.e., `op.traj_bins_q[-1,:]` in an array called  `approx_solutions`. You can use the code snippet below to initalise your outputsheduler. Make sure that the value of q_bins is set as above in exercise 1. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op = outp.HistogramOutputsheduler(integrator, \n",
    "                                 Nsteps, \n",
    "                                 varname_list=['q'],\n",
    "                                 bins_list = [q_bins],\n",
    "                                 modprnt=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note!** The histogram  `op.traj_bins_q` is not normalized! Use the command sequence \n",
    "\n",
    "    pdf_sum = np.sum(op.traj_bins_q[-1,:])\n",
    "    op.traj_bins_q[-1,:]/=pdf_sum \n",
    "   \n",
    "to normalize the histogram after each simulation run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the command \n",
    "`ref_solutions = np.load('reference_t={}d.npy'.format(int(T)),allow_pickle=False)`\n",
    "you can load a reference solution computed with a high order scheme (Stochastic Heun) using a a small stepsize (h=0.01). Use the last entry of the trajectory, i.e., `ref_solutions[-1,:]`, which corresponds to the histogram computed at time $T$. Using this reference solution compute the error sum\n",
    "$$\n",
    "\\sum_{i=1}^{12}\\mathcal{E}({\\bf 1}_{S_i},h,T)\n",
    "$$\n",
    "for $T=1$ and $T=4$. Create a loglog plot 'h vs error sum' for each value of $T$. Again include plots for the first and second order line for orientation. Repeat your numerical experiments using the Euler-Maruyama schem  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
